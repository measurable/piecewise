---
title: "Fooling Ai"
date: 2019-11-01T17:28:01+09:00
categories:
    - generic
tags:
    - generic
keywords:
inspired: https://newspeppermint.com/2019/10/31/m-deep1/?fbclid=IwAR2XzJYYiC5wcAfKCEwXo7p-OSeIUcEreDwcf42i4YUHuxsJhx58baELa28
motivation: ""
draft: true
---

https://www.nature.com/articles/d41586-019-03013-5?fbclid=IwAR2tkG4nzvL33Q7Z-chHU53sH1WTlrprM_vfTktWHh_fKsDBeZ99dbolESI

사람에게는 인식 불가능할 정도로 작은 변화를 입력에 추가하는 것만으로도 최고 수준의 신경망을 무력화시킬 수 있다.

이 문제들은 평범한 보통의 기술에서 흔히 나타나는 특이한 실수가 아니다.
DNN은 근본적으로 불안정하다. 놀라울 정도로 주어진 일을 잘 해내다가도, 익숙하지 않은 영역에 들어섰을 때 전혀 예측 불가능한 결과를 내어놓는다.

- 스티커를 몇 군데 붙여서 정지 신호를 잘못 읽게 만들 수 있다
- 안경이나 모자에 특정한 패턴을 넣어서 얼굴 인식 시스템을 속이는 것도 가능하다.
- 화이트 노이즈를 이용해 음성인식 프로그램이 가상의 문구를 듣게 하는 것도 가능하다.

프랑소와 콜레:
DNN 의 근본적인 약점을 해결할 방법은 없다. 그와 다른 연구자들은 이 단점을 해결하기 위해서는 패턴 찾기에 특화된 이 DNN에 다른 특별한 능력을 더 해야 한다고 말한다.

몇몇 전문가들은 이런 종류의 시스템이 다음 10년 동안의 주요한 AI 연구가 될 것이라 생각한다.
예를 들어,

- AI 가 자신에게 주어진 세상을 탐사하게 한다든지,
- 자신의 코드를 직접 짜고 메모리를 유지하게 하는 것 등.


크리스찬 세지디 외, 〈신경망의 흥미로운 특징들〉:
첫번째 현실 점검. 이들은 DNN 이 인식할 수 있는 특정한 사진---예를 들어 사자 사진---에 대해 몇 개의 픽셀을 바꿈으로써 전혀 다른 대상, 예를 들어 도서관으로 인식하게 할 수 있음을 보였다. 이들은 이런 조작된 사진을 ‘적대적 예제’라 불렀다.

클룬, 안 능우엔, 제이슨 요신스키:
DNN이 실제로 존재하지 않는 대상을, 예를 들어 파도 모양의 곡선 패턴에서 펭귄을 보도록 할 수 있다는 것을 보였다.

요슈아 벤지오:
기계학습을 해본 사람은 누구나 이 시스템이 한 번씩 바보 같은 결정을 내린다는 사실을 알고 있다. 놀라운 것은 그 실수의 성격이다. 우리가 전혀 생각하지 못했던 그런 종류의 실수가 나타난다.

능우엔:
사진의 대상을 조금 회전시키는 것 만으로도 현존하는 가장 뛰어난 이미지 분류 알고리듬을 무력화시킬수 있다는 것을 보였다.
헨드릭스 외:
전혀 조작을 가하지 않은 이미지에 대해서도 최신 알고리듬이, 예를 들어 버섯을 프레첼로, 잠자리를 맨홀 뚜껑으로 분류할 수 있다는 것을 보였다.

샌디 황 외:
강화학습이라는 기술을 이용해 DNN이 아타리 비디오 게임을 깨도록 만들었다. 강화학습은 AI 에게 목적을 주고, 주어진 입력의 범위에 대해 시행착오를 통해 목적에 도달하게 만드는 기술이다. 이 기술은 바둑에서 인간을 이긴 알파제로와 포커의 플루리버스에 쓰였다. 하지만 황의 팀은 또한, 화면에 한 두 개의 임의의 픽셀을 추가할 경우 AI 가 게임을 지게 할 수 있다는 것도 보였다.

아담 글리브 외:
AI의 환경에 AI의 반응을 혼란스럽게 만들수 있는 '적대적 전략'을 가진 대상을 도입할 수 있음을 보였다. 예를 들어, AI 축구선수는 AI 골키퍼를 피해 골을 넣게 학습할 수 있다. 하지만 이 AI 축구선수는 골키퍼가 바닥에 눕는 것과 같은 예상치 못한 행동을 했을 때 오히려 골을 넣지 못했다.

구글의 한 팀의 연구:
DNN 의 약점이 알려질 경우 심지어 해커들이 이 강력한 AI를 이용하게 될 수도 있다. 적대적 예제를 이용해 단순히 DNN이 잘못 예측하는 것을 넘어, 아예 AI가 다른 작업을 하게 끔 프로그램을 다시 쓰게 만들 수도 있음을 보였습니다.

클룬:
언어를 학습하는 등의 여러 종류의 신경망이 이론적으로는 다른 컴퓨터 프로그램으로 이용될 수 있다. 이론적으로는 챗봇을 이용해 당신이 원하는 어떤 프로그램도 만들 수 있다. 이게 정말 머리아픈 일이다. 클룬은 가까운 미래에 해커들이 클라우드의 신경망을 해킹해 자신의 스팸봇 회피 알고리듬을 돌리게 될 수 있다고 말한다.

던 송:
DNN 을 해커들의 봉이라 말한다. 이 시스템을 공격할 수 있는 수많은 방법들이 있다. 반면 이를 방어하기는 너무너무 어렵다.

해법의 탐구

적대적 훈련:
AI에게 더 많은 데이터를 주는 것